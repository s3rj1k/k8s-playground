# Copyright 2025 s3rj1k
# SPDX-License-Identifier: Apache-2.0

# DEBUG: ansible-pull -U https://github.com/s3rj1k/k8s-playground.git k8s/debian-playbook.yml
# ref: https://philprime.dev/guides/building-a-production-ready-kubernetes-cluster-from-scratch/lesson-8

---
- name: Kubernetes (k8s) on Debian AMD64
  hosts: localhost
  connection: local
  become: true
  gather_facts: true
  ignore_errors: false
  vars:
    KUBERNETES_VERSION: "v1.32"
    # curl -s "https://api.github.com/repos/kubernetes/kubernetes/releases/latest" | jq -r ".tag_name"
    KUBERNETES_VERSION_FULL: "v1.32.3"
    CRIO_VERSION: "v1.32"
    # curl -s "https://raw.githubusercontent.com/cilium/cilium/main/stable.txt"
    CILIUM_VERSION: "1.17.2"
    # curl -s "https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt"
    CILIUM_CLI_VERSION: "v0.18.3"
    # curl -s "https://api.github.com/repos/kubernetes-sigs/cluster-api/releases/latest" | jq -r ".tag_name"
    CLUSTERCTL_VERSION: "v1.9.6"
    # curl -s "https://api.github.com/repos/rancher/local-path-provisioner/releases/latest" | jq -r ".tag_name"
    LOCAL_PATH_PROVISIONER_VERSION: "v0.0.31"
    LB_IP_RANGE_START: ""
    LB_IP_RANGE_STOP: ""
    REGISTRY_MIRROR: ""
    WORKER_JOIN_COMMAND: ""

  pre_tasks:
    - name: Check if system is supported
      block:
        - name: Check if distribution is Debian
          fail:
            msg: "This playbook only supports Debian distributions"
          when: ansible_distribution != "Debian"

        - name: Check if architecture is AMD64
          fail:
            msg: "This playbook only supports AMD64 architecture"
          when: ansible_architecture != "x86_64"

        - name: Get Debian version
          debug:
            msg: "Running on Debian {{ ansible_distribution_version }} ({{ ansible_architecture }})"
          when:
            - ansible_distribution == "Debian"
            - ansible_architecture == "x86_64"

    - name: Wait for system to be ready
      wait_for:
        path: /var/lib/cloud/instance/boot-finished
        timeout: 600
      when: ansible_service_mgr is defined and lookup('env', 'CLOUD_INIT') != ''

  handlers:
    - name: restart sshd
      systemd:
        name: ssh
        state: restarted
        daemon_reload: yes
      when: ansible_service_mgr == 'systemd'

    - name: restart crio
      systemd:
        name: crio
        state: restarted
        daemon_reload: yes
      when: ansible_service_mgr == 'systemd'

  tasks:
    - name: Remove system users and groups
      block:
        - name: Remove users
          user:
            name: "{{ item }}"
            state: absent
            remove: yes
          loop:
            - debian
          ignore_errors: yes

        - name: Remove groups
          group:
            name: "{{ item }}"
            state: absent
          loop:
            - debian
          ignore_errors: yes

    - name: Update and upgrade system packages
      apt:
        update_cache: yes
        upgrade: yes
      register: system_upgraded

    - name: Consolidated package management
      block:
        - name: Install minimum packages required for setting up repositories
          apt:
            name:
              - apt-transport-https
              - ca-certificates
              - curl
              - gnupg
            state: present
            update_cache: yes
          when: system_upgraded is success

        - name: Create apt keyrings directory
          file:
            path: /etc/apt/keyrings
            state: directory
            mode: '0755'

        - name: Add Kubernetes repository key
          shell: |
            curl -fsSL https://pkgs.k8s.io/core:/stable:/{{ KUBERNETES_VERSION }}/deb/Release.key | \
            gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
          args:
            creates: /etc/apt/keyrings/kubernetes-apt-keyring.gpg

        - name: Add Kubernetes repository
          # apt-cache madison $(apt-cache pkgnames)
          ansible.builtin.copy:
            dest: /etc/apt/sources.list.d/kubernetes.list
            content: "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/{{ KUBERNETES_VERSION }}/deb/ /"
            mode: '0644'

        - name: Add CRI-O repository key
          shell: |
            curl -fsSL https://download.opensuse.org/repositories/isv:/cri-o:/stable:/{{ CRIO_VERSION }}/deb/Release.key | \
            gpg --dearmor -o /etc/apt/keyrings/cri-o-apt-keyring.gpg
          args:
            creates: /etc/apt/keyrings/cri-o-apt-keyring.gpg

        - name: Add CRI-O repository
          ansible.builtin.copy:
            dest: /etc/apt/sources.list.d/cri-o.list
            content: "deb [signed-by=/etc/apt/keyrings/cri-o-apt-keyring.gpg] https://download.opensuse.org/repositories/isv:/cri-o:/stable:/{{ CRIO_VERSION }}/deb/ /"
            mode: '0644'

        - name: Add Helm repository key
          shell: |
            curl -fsSL https://baltocdn.com/helm/signing.asc | \
            gpg --dearmor -o /etc/apt/keyrings/helm.gpg
          args:
            creates: /etc/apt/keyrings/helm.gpg

        - name: Add Helm repository
          ansible.builtin.copy:
            dest: /etc/apt/sources.list.d/helm.list
            content: "deb [signed-by=/etc/apt/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main"
            mode: '0644'

        - name: Update apt cache after adding repositories
          apt:
            update_cache: yes

        - name: Install remaining required packages
          apt:
            name:
              - gettext-base
              - tar
              # Locale
              - locales
              # SSH
              - openssh-server
              # GIT
              - git
              - git-lfs
              # Multipath
              - multipath-tools
              # Security
              - libseccomp2
              # Networking
              - ebtables
              - iproute2
              - libnetfilter-acct1
              - libnetfilter-cttimeout1
              - libnetfilter-log1
              - socat
              # Containers
              - buildah
              # Kubernetes
              - cri-o
              - cri-tools
              - helm
              - kubeadm
              - kubectl
              - kubelet
              # Text and JSON processing
              - gawk
              - jq
              - nano
              - sed
              - yq
              # TUI
              - mc
            state: present
            update_cache: yes
          when: system_upgraded is success

    - name: Configure SSH client
      copy:
        dest: /etc/ssh/ssh_config
        content: |
          Host *
            AddressFamily inet
            ForwardAgent yes
            PasswordAuthentication no
            # CheckHostIP no
            # HashKnownHosts no
            # StrictHostKeyChecking no

    - name: Configure SSH server
      block:
        - name: Configure root login restrictions
          lineinfile:
            path: /etc/ssh/sshd_config
            regexp: '^#?PermitRootLogin'
            line: 'PermitRootLogin prohibit-password'
          notify: restart sshd

        - name: Remove cloud-init SSH configuration
          file:
            path: /etc/ssh/sshd_config.d/60-cloudimg-settings.conf
            state: absent
          notify: restart sshd

    - name: Configure multipath
      block:
        - name: Create multipath configuration file
          copy:
            dest: /etc/multipath.conf
            content: |
              defaults {
                user_friendly_names yes
              }
            mode: '0644'
          register: multipath_conf

        - name: Enable and start multipathd service
          systemd:
            name: multipathd
            enabled: yes
            state: started

        - name: Restart multipathd service on configuration change
          systemd:
            name: multipathd
            state: restarted
          when: multipath_conf is changed

    - name: Configure kernel modules
      block:
        - name: Ensure required kernel modules are loaded
          modprobe:
            name: "{{ item }}"
            state: present
          loop:
            - overlay
            - br_netfilter

        - name: Persist required kernel modules
          copy:
            dest: /etc/modules-load.d/99-local.conf
            content: |
              overlay
              br_netfilter
            mode: '0644'

        - name: Configure kernel parameters
          copy:
            dest: /etc/sysctl.d/99-local.conf
            content: |
              fs.inotify.max_user_instances = 8192
              fs.inotify.max_user_watches = 524288
              kernel.panic = 10
              kernel.panic_on_oops = 1
              net.bridge.bridge-nf-call-ip6tables = 1
              net.bridge.bridge-nf-call-iptables = 1
              net.ipv4.conf.all.rp_filter = 1
              net.ipv4.ip_forward = 1
              net.ipv4.tcp_congestion_control = bbr
              net.ipv6.conf.all.disable_ipv6 = 0
              net.ipv6.conf.all.forwarding = 1
              vm.overcommit_memory = 1
            mode: '0644'

        - name: Apply kernel parameters
          command: sysctl --system
          changed_when: false

    - name: Disable swap
      block:
        - name: Disable swap memory
          shell: |
            swapoff -a
          when: ansible_memory_mb.swap.total != 0

        - name: Disable swap entries in fstab
          lineinfile:
            path: /etc/fstab
            regexp: '^([^#].*\s+swap\s+.*)$'
            line: '#\1'
            backrefs: yes
          when: ansible_memory_mb.swap.total != 0

    - name: Configure GRUB
      block:
        - name: Create GRUB configuration directory
          file:
            path: /etc/default/grub.d
            state: directory
            mode: '0755'

        - name: Configure GRUB settings
          copy:
            dest: /etc/default/grub.d/50-settings.cfg
            content: |
              # Set the recordfail timeout
              GRUB_RECORDFAIL_TIMEOUT=0

              # Do not wait on grub prompt
              GRUB_TIMEOUT=0

              # Set the default commandline
              GRUB_CMDLINE_LINUX_DEFAULT="console=tty1 console=ttyS0 transparent_hugepage=madvise"

              # Set the grub console type
              GRUB_TERMINAL=console
            mode: '0644'
          register: grub_config

        - name: Update GRUB configuration
          command: update-grub
          when: grub_config is changed

    - name: Install etcd network tuning script and udev rule
      block:
        - name: Create directory for scripts
          file:
            path: /usr/local/sbin
            state: directory
            mode: '0755'
            owner: root
            group: root

        - name: Install etcd network tuning script
          copy:
            dest: /usr/local/sbin/etcd-network-tuning.sh
            content: |
              #!/bin/bash

              export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

              set -o errexit  # exits immediately on any unexpected error (does not bypass traps)
              set -o nounset  # will error if variables are used without first being defined
              set -o pipefail # any non-zero exit code in a piped command causes the pipeline to fail with that code

              trap on_exit ERR
              on_exit() {
                  echo "Error setting etcd network tuning parameters for interface: ${DEV}" | systemd-cat -p emerg -t etcd-tuning
              }

              if [ "$#" -ne 1 ]; then
                  echo "Error: Usage: $0 <dev>" | systemd-cat -p emerg -t etcd-tuning
                  exit 1
              fi

              DEV=$1

              echo "Setting etcd network tuning parameters for interface: ${DEV}" | systemd-cat -p info -t etcd-tuning
              tc qdisc del dev ${DEV} root 2>/dev/null || true
              tc qdisc add dev ${DEV} root handle 1: prio bands 3
              tc filter add dev ${DEV} parent 1: protocol ip prio 1 u32 match ip sport 2380 0xffff flowid 1:1
              tc filter add dev ${DEV} parent 1: protocol ip prio 1 u32 match ip dport 2380 0xffff flowid 1:1
              tc filter add dev ${DEV} parent 1: protocol ip prio 2 u32 match ip sport 2379 0xffff flowid 1:1
              tc filter add dev ${DEV} parent 1: protocol ip prio 2 u32 match ip dport 2379 0xffff flowid 1:1

              exit 0
            mode: '0755'
            owner: root
            group: root
          register: script_install

        - name: Install udev rule for etcd network tuning
          copy:
            dest: /etc/udev/rules.d/90-etcd-network-tuning.rules
            content: |
              ACTION=="add", SUBSYSTEM=="net", SUBSYSTEMS=="pci|xen|vmbus" RUN+="/usr/local/sbin/etcd-network-tuning.sh $name"
            mode: '0644'
            owner: root
            group: root
          register: udev_rule_install

        - name: Reload udev rules if changed
          command: udevadm control --reload-rules
          when: udev_rule_install.changed

        - name: Trigger udev events for network interfaces if script or rules changed
          shell: find /sys/class/net -mindepth 1 -maxdepth 1 -type l -name "[a-z]*" -not -name "lo" -printf "%f\n" | xargs -I{} udevadm trigger --action=add --subsystem-match=net --sysname-match={}
          when: script_install.changed or udev_rule_install.changed

    - name: Configure CRI-O
      # https://github.com/cri-o/cri-o/blob/main/README.md#configuration
      block:
        - name: Create CRI-O registries mirror configuration
          copy:
            dest: /etc/containers/registries.conf.d/mirror.conf
            content: |
              [[registry]]
              prefix = "docker.io"
              location = "docker.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "quay.io"
              location = "quay.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "gcr.io"
              location = "gcr.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "registry.k8s.io"
              location = "registry.k8s.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]

              [[registry]]
              prefix = "k8s.gcr.io"
              location = "k8s.gcr.io"
              mirror = [{ location = "{{ REGISTRY_MIRROR }}" }]
            mode: '0644'
          when: REGISTRY_MIRROR is defined and REGISTRY_MIRROR | trim | length > 0
          notify: restart crio

    - name: Install clusterctl
      block:
        - name: Download clusterctl binary
          get_url:
            url: "https://github.com/kubernetes-sigs/cluster-api/releases/download/{{ CLUSTERCTL_VERSION }}/clusterctl-linux-amd64"
            dest: /usr/local/bin/clusterctl
            mode: '0755'
      when: CLUSTERCTL_VERSION is defined and CLUSTERCTL_VERSION | trim | length > 0

    - name: Initialize Kubernetes Control Plane
      block:
          # FeatureGates:
          #  - https://kubernetes.io/docs/tasks/configure-pod-container/image-volumes/
        - name: Create kubeadm configuration file
          copy:
            dest: /root/kubeadm-config.yaml
            content: |
              ---
              apiVersion: kubeadm.k8s.io/v1beta4
              kind: InitConfiguration
              nodeRegistration:
                criSocket: "unix:///var/run/crio/crio.sock"
              skipPhases:
                - addon/kube-proxy
              ---
              apiVersion: kubeadm.k8s.io/v1beta4
              kind: ClusterConfiguration
              kubernetesVersion: {{ KUBERNETES_VERSION_FULL }}
              ---
              apiVersion: kubelet.config.k8s.io/v1beta1
              kind: KubeletConfiguration
              cgroupDriver: systemd
              featureGates:
                ImageVolume: true
            mode: '0644'

        - name: Enable and start Kubelet service
          systemd:
            name: kubelet
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Enable and start CRI-O service
          systemd:
            name: crio
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Check if Kubernetes cluster is already running
          command: kubectl get nodes
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: kubectl_get_nodes
          changed_when: false
          failed_when: false

        - name: Initialize the Kubernetes Control Plane
          command: kubeadm init --config=/root/kubeadm-config.yaml
          args:
            creates: /etc/kubernetes/admin.conf
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: kubeadm_init
          changed_when: true
          failed_when: kubeadm_init.rc != 0
          when: kubectl_get_nodes.rc != 0

        - name: Create .kube directory for root user
          file:
            path: /root/.kube
            state: directory
            owner: root
            group: root
            mode: '0700'

        - name: Create symlink from admin.conf to .kube/config
          file:
            src: /etc/kubernetes/admin.conf
            dest: /root/.kube/config
            state: link
            force: true

        - name: Check if Control Plane taint exists
          shell: kubectl get nodes -o jsonpath='{.items[*].spec.taints[?(@.key=="node-role.kubernetes.io/control-plane")].key}'
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: taint_check
          changed_when: false

        - name: Remove taints from Control Plane nodes
          command: kubectl taint nodes --all node-role.kubernetes.io/control-plane-
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: remove_taint
          changed_when: remove_taint.rc == 0
          failed_when: false
          when: taint_check.stdout | length > 0

      when: WORKER_JOIN_COMMAND is not defined or WORKER_JOIN_COMMAND | trim | length == 0

    # Install Cilium as CNI (https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/)
    - name: Install Cilium CNI
      block:
        - name: Download and install Cilium CLI
          shell: |
            curl -L --fail https://github.com/cilium/cilium-cli/releases/download/{{ CILIUM_CLI_VERSION }}/cilium-linux-amd64.tar.gz | \
            tar xzf - -C /usr/local/bin
          args:
            creates: /usr/local/bin/cilium

        - name: Make Cilium CLI executable
          file:
            path: /usr/local/bin/cilium
            mode: '0755'
            state: file

        - name: Check if Cilium is already installed
          command: cilium status
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
            HOME: /root
            XDG_CACHE_HOME: /root/.cache
          register: cilium_status
          changed_when: false
          failed_when: false

        - name: Install Cilium if not already installed
          command: cilium install --version {{ CILIUM_VERSION }}
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
            HOME: /root
            XDG_CACHE_HOME: /root/.cache
          register: cilium_install
          changed_when: cilium_install.rc == 0
          failed_when: cilium_install.rc != 0
          when: cilium_status.rc != 0

        - name: Wait for Cilium to be ready
          command: cilium status --wait
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
            HOME: /root
            XDG_CACHE_HOME: /root/.cache
          register: cilium_wait
          changed_when: false
          until: cilium_wait.rc == 0
          retries: 5
          delay: 30
      when: WORKER_JOIN_COMMAND is not defined or WORKER_JOIN_COMMAND | trim | length == 0

    - name: Configure LB
      block:
        - name: Create CiliumLoadBalancerIPPool
          copy:
            dest: /root/lb-config.yaml
            content: |
              apiVersion: cilium.io/v2alpha1
              kind: CiliumLoadBalancerIPPool
              metadata:
                name: default-pool
              spec:
                blocks:
                  - start: "{{ LB_IP_RANGE_START }}"
                    stop: "{{ LB_IP_RANGE_STOP }}"
            mode: '0644'

        - name: Apply CiliumLoadBalancerIPPool configuration
          command: kubectl apply -f /root/lb-config.yaml
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: apply_result
          until: apply_result.rc == 0
          retries: 5
          delay: 30
      when:
        - WORKER_JOIN_COMMAND is not defined or WORKER_JOIN_COMMAND | trim | length == 0
        - LB_IP_RANGE_START | default("") | length > 0
        - LB_IP_RANGE_STOP | default("") | length > 0

    - name: Configure Local Path Provisioner
      block:
        - name: Apply Local Path Provisioner manifest
          command: kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/{{ LOCAL_PATH_PROVISIONER_VERSION }}/deploy/local-path-storage.yaml
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: apply_result
          until: apply_result.rc == 0
          retries: 5
          delay: 30

        - name: Set Local Path Storage as default storage class
          shell: |
            kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: default_sc_result
          until: default_sc_result.rc == 0
          retries: 5
          delay: 30
      when:
        - WORKER_JOIN_COMMAND is not defined or WORKER_JOIN_COMMAND | trim | length == 0

    - name: Initialize Kubernetes Worker Node
      block:
        - name: Enable and start Kubelet service
          systemd:
            name: kubelet
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Enable and start CRI-O service
          systemd:
            name: crio
            enabled: yes
            state: started
            daemon_reload: yes

        - name: Join the Kubernetes cluster as worker node
          command: "{{ WORKER_JOIN_COMMAND }}"
          register: worker_join
          changed_when: true
          failed_when: worker_join.rc != 0
          until: worker_join is succeeded
          retries: 5
          delay: 30
      when: WORKER_JOIN_COMMAND is defined and WORKER_JOIN_COMMAND | trim | length > 0

    - name: Mask unnecessary systemd units
      systemd:
        name: "{{ item }}"
        masked: yes
      loop:
        - apparmor.service
        - auditd.service
        - chronyd.service
        - connman.service
        - display-manager.service
        - NetworkManager.service
        - plymouth-quit-wait.service
        - plymouth-start.service
        - snapd.seeded.service

    - name: Handle system reboot check
      block:
        - name: Check if reboot is required
          stat:
            path: /var/run/reboot-required
          register: reboot_required_file

        - name: Print reboot status
          debug:
            msg: "System reboot is required"
          when: reboot_required_file.stat.exists
      when: system_upgraded is success
